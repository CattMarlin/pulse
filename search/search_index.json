{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview Pulse is an Apache 2.0 licensed log aggregation framework built on top of Solr Cloud (Cloudera Search). It can be used with applications written in any language, but was build especially for improving logging in Apache Spark Streaming applications running on Apache Hadoop. Pulse gives application users full text centralized search of their logs, flexible alerts on their logs, and works with several visualization tools. Pulse handles log lifecycle, so application developers don't have to worry about rotating or maintaining log indexes themselves. License Pulse is Apache 2.0 Licensed System Requirements A Solr Cloud installation Java 1.8 A Cloudera Manager managed cluster is recommended but not required Features Log Aggregation and Search - Add log aggregation, search, and alerts to your Java, Scala, Bash, or Python programs and scripts Alerting Flexible alerting using the Pulse Alert Engine Write alerts using the full solr query syntax. Example alerts: There was an appliction Error in the last 5 minutes My application has stopped logging messages Email and web hook integrations Log Lifecycle Management Built in rotation of logs. Keep logs for as long as you need them Automatically rotate new log indexes after a configured time period Easily search all logs Dashboarding Integration with existing dashboards for rich UIs. Visualization and search works with: Hue Search Arcadia Data Banana Hadoop Native Pulse uses Solr for document indexing and search and can be deployed on your Hadoop cluster Use existing Sentry roles to control access to log data Cloudera Manager Integration Simple deployment using CSDs and Parcels Manage and monitor Pulse from within Cloudera Manager Pulse is used for centralized logging. This diagram compares Pulse to other tools given use cases: Components Collection Roller The collection roller is responsible for creating solr indexes for new applications in Pulse and deleting old or expired log collections. Alert Engine The Alert Engine is a daemon process with a set of alertRules . Alert rules can be configured to notify developers and application users when an event happens. See the Alerting Engine for more details and configuration options. Log Collector The Log Collector is an HTTP server that receives log messages as JSON and puts them into SOLR collections. See the Log Collector for more details and configuration options. Log Appender An HTTP log appender for log4j 1.x that will post json messages to the log collector. See the Log Appender for more details. There are also log appenders for Bash and Python in the 'appenders' folder Architecture Diagram Deploying config Pulse has two configuration files, collection-roller.yml and alert-engine.yml Both of these configs are deployed via safety valves. Alert Engine Example and Collection Roller Example Place collection-roller.yml in Collection Roller Advanced Configuration Snippet (Safety Valve) for collection-roller.yml Place the alert-engine.yml in Alert Engine Advanced Configuration Snippet (Safety Valve) for alert-engine.yml Configuring Sentry for Solr If Sentry is enabled for Solr, roles and grants will need to be configured for Pulse and for each Pulse application. Add the pulse group to the Solr admin role. This assumes Sentry for Solr has been configured with an admin role. This step only needs to be done once after install. The example below assumes your admin role is named solradmin . - solrctl sentry --add-role-group solradmin pulse Create the role and grant for each application. In this example, sample_role is the name of the Solr role granting query privileges to the collection sample-app_all for the Pulse application sample-app . The sample-group group is added to that role. - solrctl sentry --create-role sample_role - solrctl sentry --grant-privilege sample_role 'collection=sample-app_all- action=Query' - solrctl sentry --add-role-group sample_role sample_group Running the application manually on a cluster Run make package which will collect all the jars into target/lib . Remove the .template suffix from these two files under the bin directory. - cp env.sh.template env.sh Change the kerberos keyTab and principal in jaas.conf to your own (you need to create one if you don't have it already) Run individual components: $ bin/collection-roller $ bin/log-collector $ bin/alert-engine Running tests Run all tests from the project root: $ make test","title":"Home"},{"location":"#overview","text":"Pulse is an Apache 2.0 licensed log aggregation framework built on top of Solr Cloud (Cloudera Search). It can be used with applications written in any language, but was build especially for improving logging in Apache Spark Streaming applications running on Apache Hadoop. Pulse gives application users full text centralized search of their logs, flexible alerts on their logs, and works with several visualization tools. Pulse handles log lifecycle, so application developers don't have to worry about rotating or maintaining log indexes themselves.","title":"Overview"},{"location":"#license","text":"Pulse is Apache 2.0 Licensed","title":"License"},{"location":"#system-requirements","text":"A Solr Cloud installation Java 1.8 A Cloudera Manager managed cluster is recommended but not required","title":"System Requirements"},{"location":"#features","text":"Log Aggregation and Search - Add log aggregation, search, and alerts to your Java, Scala, Bash, or Python programs and scripts Alerting Flexible alerting using the Pulse Alert Engine Write alerts using the full solr query syntax. Example alerts: There was an appliction Error in the last 5 minutes My application has stopped logging messages Email and web hook integrations Log Lifecycle Management Built in rotation of logs. Keep logs for as long as you need them Automatically rotate new log indexes after a configured time period Easily search all logs Dashboarding Integration with existing dashboards for rich UIs. Visualization and search works with: Hue Search Arcadia Data Banana Hadoop Native Pulse uses Solr for document indexing and search and can be deployed on your Hadoop cluster Use existing Sentry roles to control access to log data Cloudera Manager Integration Simple deployment using CSDs and Parcels Manage and monitor Pulse from within Cloudera Manager Pulse is used for centralized logging. This diagram compares Pulse to other tools given use cases:","title":"Features"},{"location":"#components","text":"Collection Roller The collection roller is responsible for creating solr indexes for new applications in Pulse and deleting old or expired log collections. Alert Engine The Alert Engine is a daemon process with a set of alertRules . Alert rules can be configured to notify developers and application users when an event happens. See the Alerting Engine for more details and configuration options. Log Collector The Log Collector is an HTTP server that receives log messages as JSON and puts them into SOLR collections. See the Log Collector for more details and configuration options. Log Appender An HTTP log appender for log4j 1.x that will post json messages to the log collector. See the Log Appender for more details. There are also log appenders for Bash and Python in the 'appenders' folder","title":"Components"},{"location":"#architecture-diagram","text":"","title":"Architecture Diagram"},{"location":"#deploying-config","text":"Pulse has two configuration files, collection-roller.yml and alert-engine.yml Both of these configs are deployed via safety valves. Alert Engine Example and Collection Roller Example Place collection-roller.yml in Collection Roller Advanced Configuration Snippet (Safety Valve) for collection-roller.yml Place the alert-engine.yml in Alert Engine Advanced Configuration Snippet (Safety Valve) for alert-engine.yml","title":"Deploying config"},{"location":"#configuring-sentry-for-solr","text":"If Sentry is enabled for Solr, roles and grants will need to be configured for Pulse and for each Pulse application. Add the pulse group to the Solr admin role. This assumes Sentry for Solr has been configured with an admin role. This step only needs to be done once after install. The example below assumes your admin role is named solradmin . - solrctl sentry --add-role-group solradmin pulse Create the role and grant for each application. In this example, sample_role is the name of the Solr role granting query privileges to the collection sample-app_all for the Pulse application sample-app . The sample-group group is added to that role. - solrctl sentry --create-role sample_role - solrctl sentry --grant-privilege sample_role 'collection=sample-app_all- action=Query' - solrctl sentry --add-role-group sample_role sample_group","title":"Configuring Sentry for Solr"},{"location":"#running-the-application-manually-on-a-cluster","text":"Run make package which will collect all the jars into target/lib . Remove the .template suffix from these two files under the bin directory. - cp env.sh.template env.sh Change the kerberos keyTab and principal in jaas.conf to your own (you need to create one if you don't have it already) Run individual components: $ bin/collection-roller $ bin/log-collector $ bin/alert-engine","title":"Running the application manually on a cluster"},{"location":"#running-tests","text":"Run all tests from the project root: $ make test","title":"Running tests"},{"location":"alerting-engine/","text":"Alert Engine An alert engine will run pre-defined queries against application logs, alerting via email if they return a number of results above or below some threshold. For example, a query could be if an application has had any error messages in the past hour. The alert engine will have - User defined queries - Send emails to a list of email addresses per query Config file Here's an example of an Alert Engine configuration file: --- applications: - name: pulse-test-100 alertRules: - query: timestamp:[NOW-10MINUTES TO NOW] AND level: ERROR retryInterval: 10 resultThreshold: 0 # If the threshold is set to `-1` it will throw an alert if no results are returned alertProfiles: - mailProfile1 emailProfiles: - name: mailProfile1 addresses: - address@company.com slackProfiles: - name: slackProfile1 url: testurl.com The alert engine takes CLI arguments including a configuration file and zookeeper hosts - because we are using CloudSolrServer to connect to Solr. The solr nodes are stored in Zookkeeper, and this gives things like load balancing for free from the client. The top-level object of the configuration file is a list of applications. An application consists of two things, alerts and profiles. Alerts tell the AlertEngine what to alert on. Profiles are used to set up connections to services like email or chat clients. As many profiles can be defined as needed, so you can send alerts through both email and Slack, or any number of services. An alert rule consists of query: Solr Query that acts as a predicate, for example this query Solr: timestamp:[NOW-10MINUTES TO NOW] AND level: ERROR will trigger an alert if any message with level 'ERROR' is found within the last 10 minutes retryInterval: the query will be run on the retry interval. The retry interval is set in minutes threshold: if the query returns more than threshold results, an alert will be triggered. The default is 0. If the threshold is set to -1 , the non-existence of documents with this query will trigger an alert. This is useful for tracking application uptime. alertProfiles: One or many alertProfiles can be defined. For each alertProfile defined in an alert, an alertProfile needs to be defined for the application Silenced applications A silenced application file can be provided --silenced-application-file silenced-applications.txt That contains one line per application that should not alert. Running the Alert Engine A helper script for running the alert engine is located at bin/alert-engine . Example usage of the Alert Engine: java -Dlogback.configurationFile=logback.xml \\ -Djava.security.auth.login.config=jaas.conf \\ -cp path-to-alert-engine-assembly io.phdata.pulse.alertengine.AlertEngineMain \\ --daemonize --zk-hosts master1.valhalla.phdata.io:2181/solr \\ --smtp-server smtp.gmail.com --smtp-user user@company.com \\ --smtp-port 25 \\ --conf example-configs/alert-engine/alert-engine.yml \\ --silenced-application-file silenced-applications.txt","title":"Alert Engine"},{"location":"alerting-engine/#alert-engine","text":"An alert engine will run pre-defined queries against application logs, alerting via email if they return a number of results above or below some threshold. For example, a query could be if an application has had any error messages in the past hour. The alert engine will have - User defined queries - Send emails to a list of email addresses per query","title":"Alert Engine"},{"location":"alerting-engine/#config-file","text":"Here's an example of an Alert Engine configuration file: --- applications: - name: pulse-test-100 alertRules: - query: timestamp:[NOW-10MINUTES TO NOW] AND level: ERROR retryInterval: 10 resultThreshold: 0 # If the threshold is set to `-1` it will throw an alert if no results are returned alertProfiles: - mailProfile1 emailProfiles: - name: mailProfile1 addresses: - address@company.com slackProfiles: - name: slackProfile1 url: testurl.com The alert engine takes CLI arguments including a configuration file and zookeeper hosts - because we are using CloudSolrServer to connect to Solr. The solr nodes are stored in Zookkeeper, and this gives things like load balancing for free from the client. The top-level object of the configuration file is a list of applications. An application consists of two things, alerts and profiles. Alerts tell the AlertEngine what to alert on. Profiles are used to set up connections to services like email or chat clients. As many profiles can be defined as needed, so you can send alerts through both email and Slack, or any number of services. An alert rule consists of query: Solr Query that acts as a predicate, for example this query Solr: timestamp:[NOW-10MINUTES TO NOW] AND level: ERROR will trigger an alert if any message with level 'ERROR' is found within the last 10 minutes retryInterval: the query will be run on the retry interval. The retry interval is set in minutes threshold: if the query returns more than threshold results, an alert will be triggered. The default is 0. If the threshold is set to -1 , the non-existence of documents with this query will trigger an alert. This is useful for tracking application uptime. alertProfiles: One or many alertProfiles can be defined. For each alertProfile defined in an alert, an alertProfile needs to be defined for the application","title":"Config file"},{"location":"alerting-engine/#silenced-applications","text":"A silenced application file can be provided --silenced-application-file silenced-applications.txt That contains one line per application that should not alert.","title":"Silenced applications"},{"location":"alerting-engine/#running-the-alert-engine","text":"A helper script for running the alert engine is located at bin/alert-engine . Example usage of the Alert Engine: java -Dlogback.configurationFile=logback.xml \\ -Djava.security.auth.login.config=jaas.conf \\ -cp path-to-alert-engine-assembly io.phdata.pulse.alertengine.AlertEngineMain \\ --daemonize --zk-hosts master1.valhalla.phdata.io:2181/solr \\ --smtp-server smtp.gmail.com --smtp-user user@company.com \\ --smtp-port 25 \\ --conf example-configs/alert-engine/alert-engine.yml \\ --silenced-application-file silenced-applications.txt","title":"Running the Alert Engine"},{"location":"building/","text":"Building Pulse Building the project sbt is used for building scala, and Make is added as a wrapper to simplify building tasks. Makefile targets are run with make target-name , full documentation can be found in the Makefile: dist : create a distribution (parcel and csd) test : run all tests package : create jars from source. This will place all jars in the target/lib director install : install parcel and CSD. This is only valid on a node running Cloudera Manager and will install the csd/parcel to /opt/cloudera/csd and /opt/cloudera/parcel-repo. It will not distribute/activate the parcel or refresh/install the CSD in Cloudera Manager Before submitting a pull request, please make sure make test and make dist both pass successfully. CSD The CSD (Custom Service Descriptor) allows Cloudera Manager to easily manage and monitor the Pulse log aggregation framework, creating 'roles' for each of the Alerting Engine, Collection Roller, and Log Collector. Building the CSD $ make Installing the CSD This is for a local/development installation only, see instalation for production installation instructions. This will copy the CSD to /opt/cloudera/csd. You must be on the Cloudera Manager node sudo make install Refresh the CSD list GET /cmf/csd/refresh Uninstall any old CSD GET /cmf/csd/uninstall?csdName=PULSE-0.1.0 Install the CSD GET /cmf/csd/install?csdName=PULSE-0.1.1 Cloudera Parcel Building the parcel At the root of the project, run $ make package This will collect all dependent jars into the lib_managed folder Then from this directory run: $ make Installing the Parcel This will copy the CSD to /opt/cloudera/csd. You must be on the Cloudera Manager node sudo make install","title":"Building Pulse"},{"location":"building/#building-pulse","text":"","title":"Building Pulse"},{"location":"building/#building-the-project","text":"sbt is used for building scala, and Make is added as a wrapper to simplify building tasks. Makefile targets are run with make target-name , full documentation can be found in the Makefile: dist : create a distribution (parcel and csd) test : run all tests package : create jars from source. This will place all jars in the target/lib director install : install parcel and CSD. This is only valid on a node running Cloudera Manager and will install the csd/parcel to /opt/cloudera/csd and /opt/cloudera/parcel-repo. It will not distribute/activate the parcel or refresh/install the CSD in Cloudera Manager Before submitting a pull request, please make sure make test and make dist both pass successfully.","title":"Building the project"},{"location":"building/#csd","text":"The CSD (Custom Service Descriptor) allows Cloudera Manager to easily manage and monitor the Pulse log aggregation framework, creating 'roles' for each of the Alerting Engine, Collection Roller, and Log Collector.","title":"CSD"},{"location":"building/#building-the-csd","text":"$ make","title":"Building the CSD"},{"location":"building/#installing-the-csd","text":"This is for a local/development installation only, see instalation for production installation instructions. This will copy the CSD to /opt/cloudera/csd. You must be on the Cloudera Manager node sudo make install Refresh the CSD list GET /cmf/csd/refresh Uninstall any old CSD GET /cmf/csd/uninstall?csdName=PULSE-0.1.0 Install the CSD GET /cmf/csd/install?csdName=PULSE-0.1.1","title":"Installing the CSD"},{"location":"building/#cloudera-parcel","text":"","title":"Cloudera Parcel"},{"location":"building/#building-the-parcel","text":"At the root of the project, run $ make package This will collect all dependent jars into the lib_managed folder Then from this directory run: $ make","title":"Building the parcel"},{"location":"building/#installing-the-parcel","text":"This will copy the CSD to /opt/cloudera/csd. You must be on the Cloudera Manager node sudo make install","title":"Installing the Parcel"},{"location":"collection-roller/","text":"Collection Roller The log collector manages log indexes for applications. An application for the log collector consists of: timestamped collections in the format _ . The 'timestamped' collections hold the actual log data. an alias pointing to the newest timestamped collection called _latest. The 'latest' alias is used for any applications writing logs (like the Log Collector) an alias pointing to all collections called _all. The 'all' alias is used for searching all collections If an application does not exist in Pulse the log collector will create the required aliases and indexes. Logs are kept for a limited amount of time (weeks or months). Logs for individual applications will actually be multiple collections, each covering a time period. Rolling After an application has been created, the collection roller will create new collections for each day and delete collections older than the configured numCollections hold limit. Configuration A Collection Roller configuration file is written in yaml and will look like: solrConfigSetDir: /etc/pulse-logging/solr-configs/ # directory containing one or many solr instancedir configs to be uploaded. The name of the config when uploaded to solr will be the name of the directory applications: # Config using all defaults - name: pulse-test-default solrConfigSetName: pulseconfigv2 # Config using options - name: pulse-test-options numCollections: 7 # (optional) number of collections to keep at any given time. Defaults to 7 shards: 1 # (optional) solr collection shards, defaults to 1 replicas: 1 # (optional) number of solr config replicas. Defaults to 1 rollPeriod: 1 # (optional) number of days before the collection is rolled solrConfigSetName: pulseconfigv2 # name of solr config to use for the collections At minimum, the configuration needs: solrConfigSetDir : These Solr configurations can contain customized schema.xml and solrconfig.xml. The solrConfigSetDir can contain multiple configurations. The configurations will be looped over and uploaded to solr each time the Collection Roller runs. applications : A list of applications The applications must contain at minimum: name and solrConfigSetName . name must be unique. solrConfigSetName must correspond to the name of a solr config directory in solrConfigSetDir Optional configuration for applications: numCollections : The number of collections to keep when rolling collections. The default is 7 rollPeriod : Rollperiod in days. Default is 1. shards : Number of shards for each collection. Default is 1. replicas : Number of replicas in each collection. Default is 1. This configuration file is passes as a CLI argument along with a list of zookeeper hosts. Running the Collection Roller A helper script to run the collection roller (mostly used for development) is here bin/collection-roller To run the collection roller from the command line looks like $ java -DXmx=2147483648 \\ -Dlogback.configurationFile=logback.xml \\ -Djava.security.auth.login.config=./jaas.conf \\ -Dsun.security.krb5.debug=false \\ -cp path-to-collection-roller-assembly io.phdata.pulse.collectionroller.CollectionRollerMain \\ --daemonize \\ --conf collection-roller.yml \\ --zk-hosts master1.valhalla.phdata.io:2181/solr","title":"Collection Roller"},{"location":"collection-roller/#collection-roller","text":"The log collector manages log indexes for applications. An application for the log collector consists of: timestamped collections in the format _ . The 'timestamped' collections hold the actual log data. an alias pointing to the newest timestamped collection called _latest. The 'latest' alias is used for any applications writing logs (like the Log Collector) an alias pointing to all collections called _all. The 'all' alias is used for searching all collections If an application does not exist in Pulse the log collector will create the required aliases and indexes. Logs are kept for a limited amount of time (weeks or months). Logs for individual applications will actually be multiple collections, each covering a time period.","title":"Collection Roller"},{"location":"collection-roller/#rolling","text":"After an application has been created, the collection roller will create new collections for each day and delete collections older than the configured numCollections hold limit.","title":"Rolling"},{"location":"collection-roller/#configuration","text":"A Collection Roller configuration file is written in yaml and will look like: solrConfigSetDir: /etc/pulse-logging/solr-configs/ # directory containing one or many solr instancedir configs to be uploaded. The name of the config when uploaded to solr will be the name of the directory applications: # Config using all defaults - name: pulse-test-default solrConfigSetName: pulseconfigv2 # Config using options - name: pulse-test-options numCollections: 7 # (optional) number of collections to keep at any given time. Defaults to 7 shards: 1 # (optional) solr collection shards, defaults to 1 replicas: 1 # (optional) number of solr config replicas. Defaults to 1 rollPeriod: 1 # (optional) number of days before the collection is rolled solrConfigSetName: pulseconfigv2 # name of solr config to use for the collections At minimum, the configuration needs: solrConfigSetDir : These Solr configurations can contain customized schema.xml and solrconfig.xml. The solrConfigSetDir can contain multiple configurations. The configurations will be looped over and uploaded to solr each time the Collection Roller runs. applications : A list of applications The applications must contain at minimum: name and solrConfigSetName . name must be unique. solrConfigSetName must correspond to the name of a solr config directory in solrConfigSetDir Optional configuration for applications: numCollections : The number of collections to keep when rolling collections. The default is 7 rollPeriod : Rollperiod in days. Default is 1. shards : Number of shards for each collection. Default is 1. replicas : Number of replicas in each collection. Default is 1. This configuration file is passes as a CLI argument along with a list of zookeeper hosts.","title":"Configuration"},{"location":"collection-roller/#running-the-collection-roller","text":"A helper script to run the collection roller (mostly used for development) is here bin/collection-roller To run the collection roller from the command line looks like $ java -DXmx=2147483648 \\ -Dlogback.configurationFile=logback.xml \\ -Djava.security.auth.login.config=./jaas.conf \\ -Dsun.security.krb5.debug=false \\ -cp path-to-collection-roller-assembly io.phdata.pulse.collectionroller.CollectionRollerMain \\ --daemonize \\ --conf collection-roller.yml \\ --zk-hosts master1.valhalla.phdata.io:2181/solr","title":"Running the Collection Roller"},{"location":"contributing/","text":"Contributing to Pulse Issues Feel free to submit issues and enhancement requests to the issue tracker . Pull Requests Please follow the build instructions here Fork the repo on GitHub Clone the project to your own machine Commit changes to your own branch Push your work back up to your fork Submit a Pull request so that we can review your changes Copyright and Licensing Pulse is Apache 2.0 licensed. License Summary You can copy and paste the Apache 2.0 license summary from below. Copyright 2018 phData Inc. Licensed under the Apache License, Version 2.0 (the License ); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an AS IS BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Contributing to Pulse"},{"location":"contributing/#contributing-to-pulse","text":"","title":"Contributing to Pulse"},{"location":"contributing/#issues","text":"Feel free to submit issues and enhancement requests to the issue tracker .","title":"Issues"},{"location":"contributing/#pull-requests","text":"Please follow the build instructions here Fork the repo on GitHub Clone the project to your own machine Commit changes to your own branch Push your work back up to your fork Submit a Pull request so that we can review your changes","title":"Pull Requests"},{"location":"contributing/#copyright-and-licensing","text":"Pulse is Apache 2.0 licensed.","title":"Copyright and Licensing"},{"location":"contributing/#license-summary","text":"You can copy and paste the Apache 2.0 license summary from below. Copyright 2018 phData Inc. Licensed under the Apache License, Version 2.0 (the License ); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an AS IS BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License Summary"},{"location":"installation/","text":"Installation Pulse can be installed as a Cloudera CSD (Custom Service Descriptor). Installing the CSD Download the latest CSD jar, see versions list below Place the jar in your Cloudera Manager CSD directory, usually /opt/cloudera/csd Modify the ownership of the jar chown cloudera-scm:cloudera-scm /opt/cloudera/csd/pulse- version .jar Restart Cloudera Manager to install the jar Installing the Parcel The parcel repo should be automatically added with the CSD. The url to add it manually: Download, distribute, activate the parcel Versions: (Note, CSDs are included in the parcel repo) 2.2.0: https://repository.phdata.io/artifactory/list/parcels-release/phdata/pulse/2.2.0-cbcd-cdh5/ 2.1.0: https://repository.phdata.io/artifactory/list/parcels-release/phdata/pulse/2.1.0-ada1-cdh5/ Installing the Pulse service Pulse can be installed through the \"Add New Service\" button for your cluster. The wizard will ask you for: smtp user : This will be the 'from' address for alerts smtp password : This is only necessary if your smtp server uses authentication smtp address : The hostname of your smtp server smtp port : The port of your smtp server Installation for use with Spark To install the log4j appender for use with Apache Spark, the log-appender-{version}.jar needs to be added to the classpath in spark-env.sh To modify the classpath in Cloudera, add this line to the spark-env.sh safety valve and redeploy client configuration: export SPARK_DIST_CLASSPATH= $SPARK_DIST_CLASSPATH:/opt/cloudera/parcels/PULSE/lib/appenders/* Ansible Installation Ansible playbooks for installing Pulse from the install folder of this repository. csd-playbook.yml Installs the CSD from the phData parcel repository. This installation method requires ansible The csd-playbook $ cd install $ ansible-playbook csd-playbook.yml -u user -i host , --extra-vars version= version dev-playbook.yml The dev playbook will install a Cloudera CSD and parcel from local artifacts $ cd install $ ansible-playbook dev-playbook.yml -u user -i host , --extra-vars version=$(sh ../version)","title":"Installation"},{"location":"installation/#installation","text":"Pulse can be installed as a Cloudera CSD (Custom Service Descriptor).","title":"Installation"},{"location":"installation/#installing-the-csd","text":"Download the latest CSD jar, see versions list below Place the jar in your Cloudera Manager CSD directory, usually /opt/cloudera/csd Modify the ownership of the jar chown cloudera-scm:cloudera-scm /opt/cloudera/csd/pulse- version .jar Restart Cloudera Manager to install the jar","title":"Installing the CSD"},{"location":"installation/#installing-the-parcel","text":"The parcel repo should be automatically added with the CSD. The url to add it manually: Download, distribute, activate the parcel Versions: (Note, CSDs are included in the parcel repo) 2.2.0: https://repository.phdata.io/artifactory/list/parcels-release/phdata/pulse/2.2.0-cbcd-cdh5/ 2.1.0: https://repository.phdata.io/artifactory/list/parcels-release/phdata/pulse/2.1.0-ada1-cdh5/","title":"Installing the Parcel"},{"location":"installation/#installing-the-pulse-service","text":"Pulse can be installed through the \"Add New Service\" button for your cluster. The wizard will ask you for: smtp user : This will be the 'from' address for alerts smtp password : This is only necessary if your smtp server uses authentication smtp address : The hostname of your smtp server smtp port : The port of your smtp server","title":"Installing the Pulse service"},{"location":"installation/#installation-for-use-with-spark","text":"To install the log4j appender for use with Apache Spark, the log-appender-{version}.jar needs to be added to the classpath in spark-env.sh To modify the classpath in Cloudera, add this line to the spark-env.sh safety valve and redeploy client configuration: export SPARK_DIST_CLASSPATH= $SPARK_DIST_CLASSPATH:/opt/cloudera/parcels/PULSE/lib/appenders/*","title":"Installation for use with Spark"},{"location":"installation/#ansible-installation","text":"Ansible playbooks for installing Pulse from the install folder of this repository.","title":"Ansible Installation"},{"location":"installation/#csd-playbookyml","text":"Installs the CSD from the phData parcel repository. This installation method requires ansible The csd-playbook $ cd install $ ansible-playbook csd-playbook.yml -u user -i host , --extra-vars version= version","title":"csd-playbook.yml"},{"location":"installation/#dev-playbookyml","text":"The dev playbook will install a Cloudera CSD and parcel from local artifacts $ cd install $ ansible-playbook dev-playbook.yml -u user -i host , --extra-vars version=$(sh ../version)","title":"dev-playbook.yml"},{"location":"log-appender/","text":"Log Appenders Log4j 1.x appenders The log4j 1.x http appender will send a post message to the log-collector process with the contents of your log message. The appender will batch messages into groups of 1000 records and will flush when a group is available, 1 second has passed. The appender will always flush all messages as soon as an ERROR level message is logged. Special Handling MDC: Fields stored in the MDC (or Mapped Diagnostic Context) will be added as a top level searchable field. Message Properties: Fields found in the message properties will be added as a top level searchable field. NDC: The NDC (or Nested Diagnostic Context) is currently ignored Example log4j configuration Here is an example log4j configuration file: log4j.rootLogger=info, stdout, http log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%5p [%t] (%F:%L) - %m%n log4j.appender.http=io.phdata.pulse.log.HttpAppender log4j.appender.http.Address=http://edge2.valhalla.phdata.io:9015/v2/events/pulse-test-100 log4j.appender.http.layout=org.apache.log4j.core.layout.JsonLayout log4j.appender.http.layout.compact=false log4j.appender.http.layout.complete=true # Info messages will cause the http client to recursively call the logger # when the connection to the log-collector is not available log4j.logger.io.phdata.pulse.shade.org.apache.http=off log4j.logger.io.phdata.pulse.shade.org.apache.wire=off It's recommended (for now) that the logs be written to file in addition to Pulse through the http appender. This appender currently doesn't currently make any availability guarantees. Example usage: $ java -cp my-jar.jar:log-appender-{version}.jar -Dlog4j.configuration=file:log4j.properties com.my.main.class (Assuming the above log4j example is named log4j.properties ) When initially configuring the logger, it can be helpful to put log4j in debug mode by adding -D log4j.debug=true to your java command string. Configuration for Standalone Application Add log-appender-{version}.jar to your classpath Installation for use with Spark To install the log4j appender for use with Apache Spark, the log-appender-{version}.jar needs to be added to the classpath in spark-env.sh To modify the classpath in Cloudera, add this line to the spark-env.sh safety valve and redeploy client configuration: export SPARK_DIST_CLASSPATH= $SPARK_DIST_CLASSPATH:/opt/cloudera/parcels/PULSE/lib/appenders/*","title":"Log Appenders"},{"location":"log-appender/#log-appenders","text":"","title":"Log Appenders"},{"location":"log-appender/#log4j-1x-appenders","text":"The log4j 1.x http appender will send a post message to the log-collector process with the contents of your log message. The appender will batch messages into groups of 1000 records and will flush when a group is available, 1 second has passed. The appender will always flush all messages as soon as an ERROR level message is logged.","title":"Log4j 1.x appenders"},{"location":"log-appender/#special-handling","text":"MDC: Fields stored in the MDC (or Mapped Diagnostic Context) will be added as a top level searchable field. Message Properties: Fields found in the message properties will be added as a top level searchable field. NDC: The NDC (or Nested Diagnostic Context) is currently ignored","title":"Special Handling"},{"location":"log-appender/#example-log4j-configuration","text":"Here is an example log4j configuration file: log4j.rootLogger=info, stdout, http log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%5p [%t] (%F:%L) - %m%n log4j.appender.http=io.phdata.pulse.log.HttpAppender log4j.appender.http.Address=http://edge2.valhalla.phdata.io:9015/v2/events/pulse-test-100 log4j.appender.http.layout=org.apache.log4j.core.layout.JsonLayout log4j.appender.http.layout.compact=false log4j.appender.http.layout.complete=true # Info messages will cause the http client to recursively call the logger # when the connection to the log-collector is not available log4j.logger.io.phdata.pulse.shade.org.apache.http=off log4j.logger.io.phdata.pulse.shade.org.apache.wire=off It's recommended (for now) that the logs be written to file in addition to Pulse through the http appender. This appender currently doesn't currently make any availability guarantees. Example usage: $ java -cp my-jar.jar:log-appender-{version}.jar -Dlog4j.configuration=file:log4j.properties com.my.main.class (Assuming the above log4j example is named log4j.properties ) When initially configuring the logger, it can be helpful to put log4j in debug mode by adding -D log4j.debug=true to your java command string.","title":"Example log4j configuration"},{"location":"log-appender/#configuration-for-standalone-application","text":"Add log-appender-{version}.jar to your classpath","title":"Configuration for Standalone Application"},{"location":"log-appender/#installation-for-use-with-spark","text":"To install the log4j appender for use with Apache Spark, the log-appender-{version}.jar needs to be added to the classpath in spark-env.sh To modify the classpath in Cloudera, add this line to the spark-env.sh safety valve and redeploy client configuration: export SPARK_DIST_CLASSPATH= $SPARK_DIST_CLASSPATH:/opt/cloudera/parcels/PULSE/lib/appenders/*","title":"Installation for use with Spark"},{"location":"log-collector/","text":"Log Collector The Log Collector is an HTTP Server that listens for log events, batches them, and writes them into a Solr Cloud cluster. The log collector removes the need for each application to authenticate with Kerberose (if enabled), and adds batching and queuing for log messages to increase the efficiency of writes to Solr Cloud. Example usage: java -cp log-collector-jar io.phdata.pulse.logcollector.LogCollector \\ --port $WEBSERVER_PORT \\ --zk-hosts $SOLR_ZK_QUORUM Endpoints /log?application= application (POST) DEPRECATED Accepts a single JSON event at a time and will insert into the log indexes of application /v2/event/ application (POST) Accepts a single JSON event at a time and will insert into the log indexes of application /v2/events/ application (POST) Accepts a JSON array of events at a time and will insert into the log indexes of application Sample JSON event: { category : io.phdata.pulse.log.HttpAppenderTest , timestamp : YYYY-MM-DDTHH:mm:ss.sssZ , level : INFO , message : Hello, World , threadName : main , ndc : ndc , properties :{ key : value }, thrown :[ java.lang.Throwable: Test , \\tat io.phdata.pulse.log.HttpAppenderTest.testRenderJson(HttpAppenderTest.java:24) , \\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) , \\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) , \\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) , \\tat java.lang.reflect.Method.invoke(Method.java:498) , \\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) , \\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) , \\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) , \\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) , \\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) , \\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) , \\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) , \\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) , \\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) , \\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) , \\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) , \\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) , \\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363) , \\tat org.junit.runner.JUnitCore.run(JUnitCore.java:137) , \\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) , \\tat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) , \\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) , \\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) ] }","title":"Log Collector"},{"location":"log-collector/#log-collector","text":"The Log Collector is an HTTP Server that listens for log events, batches them, and writes them into a Solr Cloud cluster. The log collector removes the need for each application to authenticate with Kerberose (if enabled), and adds batching and queuing for log messages to increase the efficiency of writes to Solr Cloud. Example usage: java -cp log-collector-jar io.phdata.pulse.logcollector.LogCollector \\ --port $WEBSERVER_PORT \\ --zk-hosts $SOLR_ZK_QUORUM","title":"Log Collector"},{"location":"log-collector/#endpoints","text":"/log?application= application (POST) DEPRECATED Accepts a single JSON event at a time and will insert into the log indexes of application /v2/event/ application (POST) Accepts a single JSON event at a time and will insert into the log indexes of application /v2/events/ application (POST) Accepts a JSON array of events at a time and will insert into the log indexes of application Sample JSON event: { category : io.phdata.pulse.log.HttpAppenderTest , timestamp : YYYY-MM-DDTHH:mm:ss.sssZ , level : INFO , message : Hello, World , threadName : main , ndc : ndc , properties :{ key : value }, thrown :[ java.lang.Throwable: Test , \\tat io.phdata.pulse.log.HttpAppenderTest.testRenderJson(HttpAppenderTest.java:24) , \\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) , \\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) , \\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) , \\tat java.lang.reflect.Method.invoke(Method.java:498) , \\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) , \\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) , \\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) , \\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) , \\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) , \\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) , \\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) , \\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) , \\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) , \\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) , \\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) , \\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) , \\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363) , \\tat org.junit.runner.JUnitCore.run(JUnitCore.java:137) , \\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) , \\tat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) , \\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) , \\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) ] }","title":"Endpoints"},{"location":"visualizations/","text":"Visualization Pulse uses Solr, which can use several Visualization tools, including Hue and Arcadia Data. Pulse Data Visualization using Arcadia Arcadia is visual analytics and BI software that runs natively within modern data platforms such as Apache Hadoop and the cloud. Read here for more information. Data visualization using sample arcadia dashboard extract pulse.json Create new solr connection If Solr connection is not existing in Arcadia Data, create one using this link Creating New Apache Solr Connection Create new dataset Sign into Arcadia Click on DATA Go to solr connection created in the previous steps and click on NEW DATASET Enter your Dataset title, use solr as database and finally select the solr collection that you want Click CREATE You should be able to see the new dataset created Replace dataset_name and dataset_detail from pulse.json The replace-dataset-name.sh script can be found in the visualizations/arcadia folder. Use replace-dataset-name.sh script to replace dataset_name and dataset_detail with the dataset name and Solr index name of your own dataset command ./replace-dataset-name.sh my_dataset_name Solr.my_application_all dashboard.json is ready to be imported Importing dashboard Refer to below screenshots while following the import dashboard document Click on import visual artifacts Choose pulse.json file and click on import Click on Accept and Import , also check dataset at the bottom Make sure success message appeared on window Look for phData Pulse dashboard in visuals private as shown below. Lastly examine the dashboard and functionality of filters. The dashboard will look similar to below screenshot.","title":"Visualization"},{"location":"visualizations/#visualization","text":"Pulse uses Solr, which can use several Visualization tools, including Hue and Arcadia Data.","title":"Visualization"},{"location":"visualizations/#pulse-data-visualization-using-arcadia","text":"Arcadia is visual analytics and BI software that runs natively within modern data platforms such as Apache Hadoop and the cloud. Read here for more information.","title":"Pulse Data Visualization using Arcadia"},{"location":"visualizations/#data-visualization-using-sample-arcadia-dashboard-extract-pulsejson","text":"","title":"Data visualization using sample arcadia dashboard extract pulse.json"},{"location":"visualizations/#create-new-solr-connection","text":"If Solr connection is not existing in Arcadia Data, create one using this link Creating New Apache Solr Connection","title":"Create new solr connection"},{"location":"visualizations/#create-new-dataset","text":"Sign into Arcadia Click on DATA Go to solr connection created in the previous steps and click on NEW DATASET Enter your Dataset title, use solr as database and finally select the solr collection that you want Click CREATE You should be able to see the new dataset created","title":"Create new dataset"},{"location":"visualizations/#replace-dataset_name-and-dataset_detail-from-pulsejson","text":"The replace-dataset-name.sh script can be found in the visualizations/arcadia folder. Use replace-dataset-name.sh script to replace dataset_name and dataset_detail with the dataset name and Solr index name of your own dataset command ./replace-dataset-name.sh my_dataset_name Solr.my_application_all dashboard.json is ready to be imported","title":"Replace dataset_name and dataset_detail from pulse.json"},{"location":"visualizations/#importing-dashboard","text":"Refer to below screenshots while following the import dashboard document Click on import visual artifacts Choose pulse.json file and click on import Click on Accept and Import , also check dataset at the bottom Make sure success message appeared on window Look for phData Pulse dashboard in visuals private as shown below. Lastly examine the dashboard and functionality of filters. The dashboard will look similar to below screenshot.","title":"Importing dashboard"}]}